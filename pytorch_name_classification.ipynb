{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e777d19-cfff-4d11-8a23-bacf99abc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import gzip\n",
    "import csv\n",
    "import time\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3a9dc0-dc26-4298-8cee-f16a9ad04dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da885681-e11f-44e4-a26c-170a91e3095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "\n",
    "        #读数据\n",
    "        filename = \"/Users/shenxinyi/Documents/pytorch/name/names_train.csv.gz\" if is_train_set else \"/Users/shenxinyi/Documents/pytorch/name/names_test.csv.gz\"\n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "\n",
    "        #数据元组（name,country）,将其中的name和country提取出来，并记录数量\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self. len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "\n",
    "        #将country转换成索引\n",
    "        #列表->集合->排序->列表->字典\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        #获取长度\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    #获取键值对，country(key)-index(value)\n",
    "    def __getitem__(self, index):\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx,country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name]=idx\n",
    "        return country_dict\n",
    "\n",
    "    #根据索引返回国家名\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "\n",
    "    #返回国家数目\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98a9015-d79a-4b54-a863-3baf60c57a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers =1 , bidirectional = True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        #Embedding层输入 （SeqLen，BatchSize）\n",
    "        #Embedding层输出 （SeqLen，BatchSize，HiddenSize）\n",
    "        #将原先样本总数为SeqLen，批量数为BatchSize的数据，转换为HiddenSize维的向量\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        #bidirection用于表示神经网络是单向还是双向\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional = bidirectional)\n",
    "        #线性层需要*direction\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, input, seq_lengths):\n",
    "        #对input进行转置\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        #（n_Layer * nDirections, BatchSize, HiddenSize）\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        #(SeqLen, BatchSize, HiddenSize)\n",
    "        embedding = self.embedding(input)\n",
    "\n",
    "        #对数据计算过程提速\n",
    "        #需要得到嵌入层的结果（输入数据）及每条输入数据的长度\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths)\n",
    "\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "\n",
    "        #如果是双向神经网络会有h_N^f以及h_1^b两个hidden\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c46f1b2-bc56-4175-a9d5-8bc8c3651440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_length = [name2list(name) for name in names]\n",
    "    #取出所有的列表中每个姓名的ASCII码序列\n",
    "    name_sequences = [s1[0] for s1 in sequences_and_length]\n",
    "    #将列表车行度转换为LongTensor\n",
    "    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_length])\n",
    "    #将整型变为长整型\n",
    "    countries = countries.long()\n",
    "\n",
    "    #做padding\n",
    "    #新建一个全0张量大小为最大长度-当前长度\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    #取出每个序列及其长度idx固定0\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        #将序列转化为LongTensor填充至第idx维的0到当前长度的位置\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    #返回排序后的序列及索引\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim = 0, descending = True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    return seq_tensor,seq_lengths, countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69eb3862-ec16-43b8-b9ef-bd5b575fd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainset)}]', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9c02f5-9b82-491c-9ccf-1b5ec2d9dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model……\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        percent = '%.2f' % (100*correct/total)\n",
    "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d461c5-0b59-44a6-a813-c8557d9e1135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs ... \n",
      "[0m 0s] Epoch 1 [1280/13374]loss=0.017481773998588322\n",
      "[0m 1s] Epoch 1 [2560/13374]loss=0.015342059964314102\n",
      "[0m 1s] Epoch 1 [3840/13374]loss=0.0139251205449303\n",
      "[0m 2s] Epoch 1 [5120/13374]loss=0.013092188304290176\n",
      "[0m 3s] Epoch 1 [6400/13374]loss=0.012461316399276256\n",
      "[0m 3s] Epoch 1 [7680/13374]loss=0.011901024434094628\n",
      "[0m 4s] Epoch 1 [8960/13374]loss=0.011422187156443084\n",
      "[0m 5s] Epoch 1 [10240/13374]loss=0.011024660372640938\n",
      "[0m 5s] Epoch 1 [11520/13374]loss=0.010642114038475686\n",
      "[0m 6s] Epoch 1 [12800/13374]loss=0.010363437430933119\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 4791/6700 71.51%\n",
      "[0m 7s] Epoch 2 [1280/13374]loss=0.006365378340706229\n",
      "[0m 8s] Epoch 2 [2560/13374]loss=0.006653905613347888\n",
      "[0m 9s] Epoch 2 [3840/13374]loss=0.006638768749932448\n",
      "[0m 9s] Epoch 2 [5120/13374]loss=0.006614880776032806\n",
      "[0m 10s] Epoch 2 [6400/13374]loss=0.0066264242026954885\n",
      "[0m 11s] Epoch 2 [7680/13374]loss=0.006547232631904384\n",
      "[0m 11s] Epoch 2 [8960/13374]loss=0.006490245887211391\n",
      "[0m 12s] Epoch 2 [10240/13374]loss=0.006428515905281529\n",
      "[0m 12s] Epoch 2 [11520/13374]loss=0.0064001016215317775\n",
      "[0m 13s] Epoch 2 [12800/13374]loss=0.006318730763159692\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5265/6700 78.58%\n",
      "[0m 15s] Epoch 3 [1280/13374]loss=0.005229134950786829\n",
      "[0m 15s] Epoch 3 [2560/13374]loss=0.005105446686502546\n",
      "[0m 16s] Epoch 3 [3840/13374]loss=0.005212742672301829\n",
      "[0m 17s] Epoch 3 [5120/13374]loss=0.005213669390650466\n",
      "[0m 17s] Epoch 3 [6400/13374]loss=0.00524375073146075\n",
      "[0m 18s] Epoch 3 [7680/13374]loss=0.00526392167666927\n",
      "[0m 18s] Epoch 3 [8960/13374]loss=0.0051701948678653156\n",
      "[0m 19s] Epoch 3 [10240/13374]loss=0.005118571239290759\n",
      "[0m 20s] Epoch 3 [11520/13374]loss=0.005104601403905285\n",
      "[0m 20s] Epoch 3 [12800/13374]loss=0.005062684738077223\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5385/6700 80.37%\n",
      "[0m 22s] Epoch 4 [1280/13374]loss=0.004592306353151799\n",
      "[0m 23s] Epoch 4 [2560/13374]loss=0.004362109478097409\n",
      "[0m 23s] Epoch 4 [3840/13374]loss=0.004333247904044887\n",
      "[0m 24s] Epoch 4 [5120/13374]loss=0.004350864747539163\n",
      "[0m 24s] Epoch 4 [6400/13374]loss=0.004338589622639119\n",
      "[0m 25s] Epoch 4 [7680/13374]loss=0.004361131694167852\n",
      "[0m 26s] Epoch 4 [8960/13374]loss=0.0043453806711893\n",
      "[0m 26s] Epoch 4 [10240/13374]loss=0.004339324132888578\n",
      "[0m 27s] Epoch 4 [11520/13374]loss=0.0043220369636805525\n",
      "[0m 27s] Epoch 4 [12800/13374]loss=0.004312444007955492\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5501/6700 82.10%\n",
      "[0m 29s] Epoch 5 [1280/13374]loss=0.003559730132110417\n",
      "[0m 30s] Epoch 5 [2560/13374]loss=0.0036989493295550347\n",
      "[0m 30s] Epoch 5 [3840/13374]loss=0.003689656398879985\n",
      "[0m 31s] Epoch 5 [5120/13374]loss=0.0037440766347572206\n",
      "[0m 32s] Epoch 5 [6400/13374]loss=0.0037293233256787063\n",
      "[0m 32s] Epoch 5 [7680/13374]loss=0.003737822202189515\n",
      "[0m 33s] Epoch 5 [8960/13374]loss=0.003720961095366095\n",
      "[0m 33s] Epoch 5 [10240/13374]loss=0.003723572863964364\n",
      "[0m 34s] Epoch 5 [11520/13374]loss=0.0037147953097398084\n",
      "[0m 35s] Epoch 5 [12800/13374]loss=0.003757179812528193\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5528/6700 82.51%\n",
      "[0m 36s] Epoch 6 [1280/13374]loss=0.0031893295468762516\n",
      "[0m 37s] Epoch 6 [2560/13374]loss=0.0032885378110222518\n",
      "[0m 38s] Epoch 6 [3840/13374]loss=0.0032640290834630528\n",
      "[0m 38s] Epoch 6 [5120/13374]loss=0.003215476815239526\n",
      "[0m 39s] Epoch 6 [6400/13374]loss=0.003139150261413306\n",
      "[0m 39s] Epoch 6 [7680/13374]loss=0.003195593934894229\n",
      "[0m 40s] Epoch 6 [8960/13374]loss=0.0032759557561283666\n",
      "[0m 41s] Epoch 6 [10240/13374]loss=0.00322914609714644\n",
      "[0m 41s] Epoch 6 [11520/13374]loss=0.003294039961312794\n",
      "[0m 42s] Epoch 6 [12800/13374]loss=0.0032976681261789056\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5585/6700 83.36%\n",
      "[0m 44s] Epoch 7 [1280/13374]loss=0.002673480659723282\n",
      "[0m 45s] Epoch 7 [2560/13374]loss=0.0028188366908580066\n",
      "[0m 45s] Epoch 7 [3840/13374]loss=0.002876978173541526\n",
      "[0m 46s] Epoch 7 [5120/13374]loss=0.0028623018879443407\n",
      "[0m 47s] Epoch 7 [6400/13374]loss=0.0028534653922542928\n",
      "[0m 47s] Epoch 7 [7680/13374]loss=0.0028455364692490546\n",
      "[0m 48s] Epoch 7 [8960/13374]loss=0.0028959715057031384\n",
      "[0m 49s] Epoch 7 [10240/13374]loss=0.0029145563559723085\n",
      "[0m 49s] Epoch 7 [11520/13374]loss=0.002916634712730431\n",
      "[0m 50s] Epoch 7 [12800/13374]loss=0.002903419373324141\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5609/6700 83.72%\n",
      "[0m 52s] Epoch 8 [1280/13374]loss=0.00228179981932044\n",
      "[0m 52s] Epoch 8 [2560/13374]loss=0.002508158306591213\n",
      "[0m 53s] Epoch 8 [3840/13374]loss=0.00246303768750901\n",
      "[0m 54s] Epoch 8 [5120/13374]loss=0.002537416946142912\n",
      "[0m 54s] Epoch 8 [6400/13374]loss=0.0025485192937776445\n",
      "[0m 55s] Epoch 8 [7680/13374]loss=0.002560968161560595\n",
      "[0m 56s] Epoch 8 [8960/13374]loss=0.0025485800828651656\n",
      "[0m 56s] Epoch 8 [10240/13374]loss=0.0025486945858574474\n",
      "[0m 57s] Epoch 8 [11520/13374]loss=0.0025435325689613817\n",
      "[0m 58s] Epoch 8 [12800/13374]loss=0.0025466559384949507\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5638/6700 84.15%\n",
      "[0m 59s] Epoch 9 [1280/13374]loss=0.0023714397102594376\n",
      "[1m 0s] Epoch 9 [2560/13374]loss=0.002360579546075314\n",
      "[1m 1s] Epoch 9 [3840/13374]loss=0.0022410896529133123\n",
      "[1m 1s] Epoch 9 [5120/13374]loss=0.0021559869637712836\n",
      "[1m 2s] Epoch 9 [6400/13374]loss=0.0021607461012899875\n",
      "[1m 3s] Epoch 9 [7680/13374]loss=0.0021490374036754172\n",
      "[1m 3s] Epoch 9 [8960/13374]loss=0.0021650820022581945\n",
      "[1m 4s] Epoch 9 [10240/13374]loss=0.002179092883307021\n",
      "[1m 5s] Epoch 9 [11520/13374]loss=0.0021962491549654965\n",
      "[1m 5s] Epoch 9 [12800/13374]loss=0.0022061964706517755\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5641/6700 84.19%\n",
      "[1m 7s] Epoch 10 [1280/13374]loss=0.0017285837791860103\n",
      "[1m 8s] Epoch 10 [2560/13374]loss=0.0017960402939934284\n",
      "[1m 8s] Epoch 10 [3840/13374]loss=0.001807843882124871\n",
      "[1m 9s] Epoch 10 [5120/13374]loss=0.0017972389323404059\n",
      "[1m 10s] Epoch 10 [6400/13374]loss=0.0017649398581124842\n",
      "[1m 10s] Epoch 10 [7680/13374]loss=0.0017652940451322744\n",
      "[1m 11s] Epoch 10 [8960/13374]loss=0.001767309573811612\n",
      "[1m 12s] Epoch 10 [10240/13374]loss=0.0018047260731691495\n",
      "[1m 12s] Epoch 10 [11520/13374]loss=0.001830237915015055\n",
      "[1m 13s] Epoch 10 [12800/13374]loss=0.0018687503703404217\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5667/6700 84.58%\n",
      "[1m 15s] Epoch 11 [1280/13374]loss=0.001657238823827356\n",
      "[1m 15s] Epoch 11 [2560/13374]loss=0.0015791842102771624\n",
      "[1m 16s] Epoch 11 [3840/13374]loss=0.0015483122881657133\n",
      "[1m 17s] Epoch 11 [5120/13374]loss=0.0015393436013255268\n",
      "[1m 17s] Epoch 11 [6400/13374]loss=0.0015515933616552502\n",
      "[1m 18s] Epoch 11 [7680/13374]loss=0.0015489539393456653\n",
      "[1m 19s] Epoch 11 [8960/13374]loss=0.001591488703187289\n",
      "[1m 19s] Epoch 11 [10240/13374]loss=0.00159009802955552\n",
      "[1m 20s] Epoch 11 [11520/13374]loss=0.0016244746298373987\n",
      "[1m 21s] Epoch 11 [12800/13374]loss=0.001643356357817538\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5672/6700 84.66%\n",
      "[1m 22s] Epoch 12 [1280/13374]loss=0.0012297769368160515\n",
      "[1m 23s] Epoch 12 [2560/13374]loss=0.0013095342379529028\n",
      "[1m 24s] Epoch 12 [3840/13374]loss=0.001282760863735651\n",
      "[1m 24s] Epoch 12 [5120/13374]loss=0.0012790843742550352\n",
      "[1m 25s] Epoch 12 [6400/13374]loss=0.0013003971322905273\n",
      "[1m 26s] Epoch 12 [7680/13374]loss=0.0013248440625223642\n",
      "[1m 26s] Epoch 12 [8960/13374]loss=0.0013342379991497313\n",
      "[1m 27s] Epoch 12 [10240/13374]loss=0.001346615338115953\n",
      "[1m 28s] Epoch 12 [11520/13374]loss=0.0013473488280497906\n",
      "[1m 28s] Epoch 12 [12800/13374]loss=0.001387219366733916\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5635/6700 84.10%\n",
      "[1m 30s] Epoch 13 [1280/13374]loss=0.0011862667452078313\n",
      "[1m 31s] Epoch 13 [2560/13374]loss=0.0011521707172505557\n",
      "[1m 31s] Epoch 13 [3840/13374]loss=0.0011187830998096616\n",
      "[1m 32s] Epoch 13 [5120/13374]loss=0.001146058991434984\n",
      "[1m 33s] Epoch 13 [6400/13374]loss=0.0011683686589822172\n",
      "[1m 33s] Epoch 13 [7680/13374]loss=0.001156098263648649\n",
      "[1m 34s] Epoch 13 [8960/13374]loss=0.0011681474404343004\n",
      "[1m 35s] Epoch 13 [10240/13374]loss=0.001188740033103386\n",
      "[1m 35s] Epoch 13 [11520/13374]loss=0.001195213970883439\n",
      "[1m 36s] Epoch 13 [12800/13374]loss=0.0012022285244893283\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5660/6700 84.48%\n",
      "[1m 38s] Epoch 14 [1280/13374]loss=0.0008446567633654922\n",
      "[1m 38s] Epoch 14 [2560/13374]loss=0.0009098700975300744\n",
      "[1m 39s] Epoch 14 [3840/13374]loss=0.0008398651756579056\n",
      "[1m 40s] Epoch 14 [5120/13374]loss=0.0008877879205101636\n",
      "[1m 40s] Epoch 14 [6400/13374]loss=0.0009331451012985781\n",
      "[1m 41s] Epoch 14 [7680/13374]loss=0.0009681852034797582\n",
      "[1m 42s] Epoch 14 [8960/13374]loss=0.0009833452345836642\n",
      "[1m 42s] Epoch 14 [10240/13374]loss=0.0009852365499682491\n",
      "[1m 43s] Epoch 14 [11520/13374]loss=0.0010068693925859406\n",
      "[1m 44s] Epoch 14 [12800/13374]loss=0.001017764842545148\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5656/6700 84.42%\n",
      "[1m 45s] Epoch 15 [1280/13374]loss=0.0008536426874343305\n",
      "[1m 46s] Epoch 15 [2560/13374]loss=0.0008296815998619422\n",
      "[1m 47s] Epoch 15 [3840/13374]loss=0.0008248970843851566\n",
      "[1m 47s] Epoch 15 [5120/13374]loss=0.0008583234593970701\n",
      "[1m 48s] Epoch 15 [6400/13374]loss=0.0008763298951089383\n",
      "[1m 49s] Epoch 15 [7680/13374]loss=0.0008863501444769402\n",
      "[1m 49s] Epoch 15 [8960/13374]loss=0.0008793688578797238\n",
      "[1m 50s] Epoch 15 [10240/13374]loss=0.0008881582645699382\n",
      "[1m 51s] Epoch 15 [11520/13374]loss=0.0008856243854905996\n",
      "[1m 51s] Epoch 15 [12800/13374]loss=0.000902129597379826\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5646/6700 84.27%\n",
      "[1m 53s] Epoch 16 [1280/13374]loss=0.0007347895589191467\n",
      "[1m 54s] Epoch 16 [2560/13374]loss=0.0007138102911994793\n",
      "[1m 55s] Epoch 16 [3840/13374]loss=0.0007191120511076103\n",
      "[1m 55s] Epoch 16 [5120/13374]loss=0.0007502482520067133\n",
      "[1m 56s] Epoch 16 [6400/13374]loss=0.0007614215079229325\n",
      "[1m 56s] Epoch 16 [7680/13374]loss=0.0007647693608305417\n",
      "[1m 57s] Epoch 16 [8960/13374]loss=0.0007634915436418461\n",
      "[1m 58s] Epoch 16 [10240/13374]loss=0.0007785687506839167\n",
      "[1m 58s] Epoch 16 [11520/13374]loss=0.0007902534410176385\n",
      "[1m 59s] Epoch 16 [12800/13374]loss=0.0008115907388855703\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5617/6700 83.84%\n",
      "[2m 1s] Epoch 17 [1280/13374]loss=0.000620006350800395\n",
      "[2m 2s] Epoch 17 [2560/13374]loss=0.0005947997880866752\n",
      "[2m 2s] Epoch 17 [3840/13374]loss=0.0006292143642591933\n",
      "[2m 3s] Epoch 17 [5120/13374]loss=0.0006402693339623511\n",
      "[2m 3s] Epoch 17 [6400/13374]loss=0.0006795416562817991\n",
      "[2m 4s] Epoch 17 [7680/13374]loss=0.0006906381798520064\n",
      "[2m 5s] Epoch 17 [8960/13374]loss=0.0007037623411244048\n",
      "[2m 5s] Epoch 17 [10240/13374]loss=0.0007067469199682819\n",
      "[2m 6s] Epoch 17 [11520/13374]loss=0.0007161741296941829\n",
      "[2m 7s] Epoch 17 [12800/13374]loss=0.0007285482081351802\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5614/6700 83.79%\n",
      "[2m 8s] Epoch 18 [1280/13374]loss=0.0005316876049619168\n",
      "[2m 9s] Epoch 18 [2560/13374]loss=0.0005634144297800958\n",
      "[2m 10s] Epoch 18 [3840/13374]loss=0.0005794849266142894\n",
      "[2m 10s] Epoch 18 [5120/13374]loss=0.0006035523299942724\n",
      "[2m 11s] Epoch 18 [6400/13374]loss=0.0006251999887172132\n",
      "[2m 12s] Epoch 18 [7680/13374]loss=0.0006425304896159408\n",
      "[2m 12s] Epoch 18 [8960/13374]loss=0.0006493731364441503\n",
      "[2m 13s] Epoch 18 [10240/13374]loss=0.000658604077398195\n",
      "[2m 14s] Epoch 18 [11520/13374]loss=0.000650105294254091\n",
      "[2m 14s] Epoch 18 [12800/13374]loss=0.0006717448274139315\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5640/6700 84.18%\n",
      "[2m 16s] Epoch 19 [1280/13374]loss=0.0006141648787888698\n",
      "[2m 17s] Epoch 19 [2560/13374]loss=0.0005262569677142892\n",
      "[2m 18s] Epoch 19 [3840/13374]loss=0.0005219086951304537\n",
      "[2m 18s] Epoch 19 [5120/13374]loss=0.0005317066639690893\n",
      "[2m 19s] Epoch 19 [6400/13374]loss=0.0005513328083907254\n",
      "[2m 20s] Epoch 19 [7680/13374]loss=0.0005579871268613109\n",
      "[2m 20s] Epoch 19 [8960/13374]loss=0.000562853658630047\n",
      "[2m 21s] Epoch 19 [10240/13374]loss=0.0005789462646134779\n",
      "[2m 22s] Epoch 19 [11520/13374]loss=0.000605243261573681\n",
      "[2m 22s] Epoch 19 [12800/13374]loss=0.0006081514815741685\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5615/6700 83.81%\n",
      "[2m 24s] Epoch 20 [1280/13374]loss=0.0004932805255521089\n",
      "[2m 25s] Epoch 20 [2560/13374]loss=0.0004780627728905529\n",
      "[2m 25s] Epoch 20 [3840/13374]loss=0.0004724539721792098\n",
      "[2m 26s] Epoch 20 [5120/13374]loss=0.0004770816742166062\n",
      "[2m 27s] Epoch 20 [6400/13374]loss=0.0005041222729778383\n",
      "[2m 27s] Epoch 20 [7680/13374]loss=0.0005001259379544839\n",
      "[2m 28s] Epoch 20 [8960/13374]loss=0.0005329285335652198\n",
      "[2m 29s] Epoch 20 [10240/13374]loss=0.0005607606558442058\n",
      "[2m 29s] Epoch 20 [11520/13374]loss=0.0005690895033088357\n",
      "[2m 30s] Epoch 20 [12800/13374]loss=0.000586893146901275\n",
      "evaluating trained model……\n",
      "Test set: Accuracy 5596/6700 83.52%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAr5klEQVR4nO3deZxcVZ338c+vt/SWpZMOnaWzJ5BAiCEJCbuJBAiCiTioAQZlBkTF8Cg6jvjoYHR0nlEfR1QYHfRxcEEioECEaNiSAYVAFhLIQrbOvnZn7y29/Z4/6nYs2uruSqpvV3XX9/161St3OffWr29X6tf3nHPPMXdHRESkpYxkByAiIqlJCUJERGJSghARkZiUIEREJCYlCBERiSkr2QF0lOLiYh8+fHiyw2hVVVUVBQUFyQ6jVYovMYovMYovMYnEt3Llygp37x9zp7t3i9fkyZM9lS1ZsiTZIbRJ8SVG8SVG8SUmkfiAFd7K96qqmEREJCYlCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJSQlCRERi6jYPyomksqYm50RtA8dq6jlaU8fR6nqO1tRzrLqOYzX1TBxSxKWj+2FmyQ5V5BQlCJEE1DU08crmcl7cXs+q5zdxrLqOozX170oAR2vqOV5TT1M7U69MHdGXL15zDhcO79s5wYu0QwlC5DS5O6t2HuXJN3fzzFv7OFpdD4Bt3Eyv3Gz65GfTJy+b3vk5DOubf2q9V142ffJz6JMXlMnPpndeDnk5mfxu5W4eWLKFD//kNd57dn++cPXZTCjtk9wfVNKeEoRInHYequb3b+7mqTf3sP1QNT2yMrjmvAHcMGkwVTvWce3M6WRmnFkV0ccvGc5Hpgzhl69t58f/s5XZD/yFa84r4fNXncM5A3p28E8Scby2nsVr9/Ps2/s4Ul1Pr9wsCntEXj1zsynMzaJnjyx65mZRmPvX7T1PLWdRkJNFxhn+zJL6lCBE2nCsup5n3t7Lk6v2sGLHEczgohH9uGvGaK4dP4CeudkALN23/oyTQ7O8nEw++d5R3DxtKD//83Z+9koZz61/mdnvGcQ9M89meHHig8XV1jey5J2DLFyzlxffOUhdQxND+uYxoriQytp69h+rpfJkA5W1DZw42RDXOQt7ZHFWrx4M71fAsH75DOubz7DiAob3K6C0KI/sTPWF6aqUIERaqGtoYunGgzz55h5e3HCQusYmRp9VyD/POocPThzMoD55ob5/z9xsPjtzDB+7eBj/9XIZD7+6jWfe2seHJ5dy95VjGHya79/Q2MTaigaeeXwNi9fu58TJBooLe3Dz1KHMmTiIiUP6xGwcb2pyquoaOFHbQOXJyL8nautPLTcnkRNBYtl+qJplZYeorms8dY7MDGNwnzyG9cs/lUCG9ytgeHE+pUX55GZnJny9JDxKECJE2hXe3HWUJ1ft4Zm39nKkup7iwhxuuWgoH7qglPGDe3V6D6OighzuvXYs/3jZcP5zyVZ+8/pOfr9qDzdPG8pdM0ZxVs/cVo9tbif5w5q9PPPWXioq6+jZYz+zxg9gzsTBXDSyL1nt/GWfkWFBlVJ23DG7O+WVJ9lxqJrtFVXsPFzN9kPV7DhUxVOr93Ci9q93JWYwsFcuw/oVcJbVcfbEmtCTr5weJQjpVtyd2vomqusaqKlvpKaukergVVPfQE3dX/dV10X2n6htYMnGg2yrqKJHVgZXnVvChyYN5vIx/VOieuSsnrnMn30en7hiJA+8tJlfLdvBguU7+fglw/nUFaMoKsg5VXbj/hMsXLOHhWv2sutwDTlZGcwcdxajso7wmQ/NCP0vdjPjrJ65nNUz9296Y7k7R6vr2X4oSBwVkcSxtaKKhbvq+cO3X+J9Y0u45aKhXDGmf8JVdp3B3Vm/7zgA5w7s/D8iwhZqgjCzWcAPgEzgZ+7+7y32DwV+AfQJytzr7ota7F8PzHf3/xtmrNL1nKit56k39/D4yt3sOVITSQj1jXg73Ulb6pGVwcQhffj0e0cx6/wB9DqNv5g70+A+efyfD03gk1eM4v4XNvHQy2U8smwnt182gh7ZGSxcvZd39p8gM8O4dHQxn73ybK45r4SeudksXbo06dU5ZkZRQQ5FBTlcMLToXfseX/QS2zIG8diKXbyw4QClRXncNHUoH5kyhP49eyQp4tbtOVrDU2/u4ck397DlYCUAI4sLmD1xELPfM4iR/QuTHGHHCC1BmFkm8CBwFbAbWG5mC919fVSxrwKPufuPzexcYBEwPGr/fwB/DCtG6ZrW7jnGI6/v4OnVe6mua+Tcgb24ZvwA8rMzycuJvPKzM8nPySL31HKwPSeLvOzm5UzysjO7XC+c4cUF3D/3Au6aMZr/eG4TP3hxMwCThxXx9dnn8f7zB6bkl2pb+udn8OHpY/nczLN5bv1+Hlm2k+8u3sj3n9/ENeMHcMu0oVw8MrkPEp6oreePa/fz5Ko9LNt2CHeYMqyIb90wngwzFq7eyw9e3Mz9L2zm/MG9mTNxENdPGMSA3q1XBaa6MO8gpgJb3L0MwMwWAHOI3BE0c6BXsNwb2Nu8w8w+CGwDqkKMUbqIk43OY8t38cjrO1iz+xi52Rl8YMIgbrloGO8p7d3tbu3jcXZJT35y62S2lleSk5nBkL75yQ4pYTlZGVw/IfLFuuVgJY++sZMnVu7m2bf2MbK4gJunDeXGyaX0yc9p/2QdoKGxiVe2VPCT1bWsefEFauubGN4vn89deTY3XDCYof3+es1vmjqU/cdqeeatvSxcs5dvPruBby3awLQRfZkzcTDXjh/QaXF3FPPTvR+P98RmNwKz3P2OYP1WYJq7z4sqMxB4DigCCoCZ7r7SzAqB54ncffwTUBmrisnM7gTuBCgpKZm8YMGCUH6WjlBZWUlhYeredqZqfHtONLFkVz1/2VNPTaMxqNCYUZrNJYOzKMhOnaSQqtevWVeOr67RWb6/gSW7GthytImsDJg2IIsZQ7IY1Sejw/84cHd2HG/i1b0NLNvXyPE6Jz/LuWhg5HM3qnd877m/qoll+xpYtreB/dVOpsH5xZlcNCiLC/pn0iOr4+JO5Pc7Y8aMle4+Jda+ZDdS3wQ87O7fM7OLgV+Z2XhgPvB9d69s6xfh7g8BDwFMmTLFp0+fHn7EZ2jp0qUovvicbGjkT2sj1QxvbD9MTmYGk87K4vOzp3Lh8KKUvFtIpesXS1eP72rgK8CGfcf5zes7efLNPfxlby1jB/TklmlDuXR0caT6MKg2zMk6/c4Fe4/W8NTqSLvC5oPV5GRm8L6xJdwwaTCZBzYw830zTvucc4kknHV7j/P06j38Yc0+frKmlvycTK46t4Q5Ewd1SGeIsH6/YSaIPcCQqPXSYFu024FZAO7+mpnlAsXANOBGM/sOkQbsJjOrdfcHQoxXkmzHoSp+88ZOHl+xm8NVdQzrl8+Xrx3LjZNLeXvFa0wdoTGK0t24gb341w+O595rx7JwzV5+vWwH//L0ur8pl5Vh72pnysvJIj9Yzw3apCL7ssjNzmD1rqO8VhZpV5g8rIhvfnA8108YeKpKaGn5O2ccs5kxfnBvxg/uzZevHccb2w/z9Oq9/HHtPp5evZei/GxmjivhsjHFXDKqOKXaj8JMEMuBMWY2gkhimAvc3KLMTuBK4GEzGwfkAuXufnlzATObT6SKScmhG6qtb+Sldw7y6Bs7eWVzBZkZxlXjIl0dLx1V3OUakKVzFPTI4qapQ5l74RDW7jnO1vLKoDtzAzV1je/qxlxd30hN0LW58mQD5SdOnur6XFsfOWZI33w+e+UYbrhgMMP6Jf7EemsyMoyLRvbjopH9+Prs83hlczlPr97Lc+sP8PjK3QCMHdCTy0YXc+mYYqaN6Et+TvIqekJ7Z3dvMLN5wGIiXVh/7u7rzOwbwAp3Xwh8Afipmd1DpMH6Ng+rUURSRm19Iy9vKufZt/fxwvoDVNU1MrB3Lp+/6mw+euEQSnp13V4f0rnMjPNLe3N+ae8zPoe7J6XaMicrgyvHlXDluBIam5x1e4/x5y0V/GVLBb9ctoOf/Xkb2ZnGpKFFpxLGhMG9233AsSOFmpqCZxoWtdh2X9TyeuDSds4xP5TgpFOdbGjklU0VPPv2Pp5ff4DKkw0U5Wcze+Jgrp8wkGkj2n+yVyQMqdCmlZlhTCjtw4TSPtw1fTQ1dY2s2HH4VML4jxc28b3nN9GzRxYXjerHZaOLuWxMMSOLC0KNP9mN1NKN1TU08ect5Tzz1j6eX3eAEycb6JOfzfUTBnLdhIFcNLJfSjypLJJq8nIyuXxMfy4f0x+Aw1V1vLb1EH/eUs4rmyt4fv0BAAb2zuXS0cWc1dDA9BDiUIKQDlXX0MRftlbw7Fv7eG7dfo7XNtArN4tZ4wdw3YSBXDq6WElB5DT1LcjhuuAPK4gMPd98d/HChgOU9Gjkn0N4XyUISVh9YxOvbj3Es2/tZfG6AxyrqadnbhZXnzuA64OkcCbdDkUktqH98rm531BunjaUpibnmeeXhvI+ShCSkFU7jzDvkVXsPVZLYY8srj63hOsmDOSyMcX0yNJQziJhy8gwevUIpx1CCULO2II3dnLf0+so6d2D/7p1Mu89u3/SB4QTkY6jBCGnra6hia//YR2PvL6Ty8cU86ObLuhyY8yISPuUIOS0HDxey6cfWcXKHUf49PRR/NPV53SJcftF5PQpQUjcVu44zKd/vYoTtQ08ePOkUz0qRKR7UoKQuPzm9Z18beFaBvXJ45e3T2XsgF7tHyQiXZoShLTpZEMj8xeu49E3dvHes/vzw7kX0Ds/NWdcE5GOpQQhrTpwvJZP/Xolb+48yl3TR/EFtTeIpBUlCIlpxfbDfPqRVVSdbOA/b5nE+89Xe4NIulGCkHdxdx55fSdf/8M6BvfJ45E7pnF2Sc9khyUiSaAEIafU1jfytafX8dsVu5hxTn/un3sBvfPU3iCSrpQgBIDDtU189KFlrNl1lLvfN5rPzTxb7Q0iaU4JQlhWdoj5r9bQSB0/+fvJzBo/INkhiUgKUIJIU8dq6nnmrb08vmI3q3cdpSTf+PUnL2WM2htEJKAEkUYam5xXt1bw+IrdLF63n5MNTZxT0pOvXjeOwSd3KDmIyLsoQaSB7RVV/G7Vbn63cjd7j9XSKzeLj0wZwoenlHL+4N6YGUuX7kx2mCKSYpQguqmqkw08+/Y+nlixmze2HybD4PIx/fnf141j5rgSDcstIu1SguhG3J03th3m8ZW7WfT2PqrrGhlRXMAXrzmHv5tUyoDeuckOUUS6kFAThJnNAn4AZAI/c/d/b7F/KPALoE9Q5l53X2RmVwH/DuQAdcAX3f2lMGPtyvYdq+HxFbt5YuVudh6uprBHFrPfM4gbJ5cyeVgRZuquKiKnL7QEYWaZwIPAVcBuYLmZLXT39VHFvgo85u4/NrNzgUXAcKAC+IC77zWz8cBiYHBYsXZluw5XM+v+l6mqa+Tikf343MwxzBo/gPwc3RyKSGLC/BaZCmxx9zIAM1sAzAGiE4QDzeNG9wb2Arj7m1Fl1gF5ZtbD3U+GGG+X4+7c9/RaAF74/BWMPku9kESk45i7h3NisxuBWe5+R7B+KzDN3edFlRkIPAcUAQXATHdfGeM8n3L3mTHe407gToCSkpLJCxYsCOVn6QiVlZUUFhZ26DlX7G/ggdUnuWlsDtcMT2xIjDDi60iKLzGKLzHdOb4ZM2asdPcpMXe6eygv4EYi7Q7N67cCD7Qo83ngC8HyxUTuLjKi9p8HbAVGtfd+kydP9lS2ZMmSDj3fidp6n/atF3zW/S97fUNjwufr6Pg6muJLjOJLTHeOD1jhrXyvZpxRyonPHmBI1HppsC3a7cBjAO7+GpALFAOYWSnwJPAxd98aYpxd0v3Pb+LAiVq+dcN4sjLD/DWKSLoK85tlOTDGzEaYWQ4wF1jYosxO4EoAMxtHJEGUm1kf4FkivZr+EmKMXdL6vcf571e3M/fCoUwaWpTscESkmwotQbh7AzCPSA+kDUR6K60zs2+Y2eyg2BeAT5jZGuBR4LbglmceMBq4z8xWB6+zwoq1K2lqcr7y1Nv0ycvmS7POSXY4ItKNhdoX0t0XEem6Gr3tvqjl9cClMY77JvDNMGPrqhYs38WbO4/yvQ+/hz75OckOR0S6MVVedyEVlSf59p/eYdqIvnxokh4LEZFwKUF0If+2aAPVdQ1864bxejpaREKnBNFFvLb1EL9ftYc7rxipB+JEpFMoQXQBdQ1NfPWptxnSN495M8YkOxwRSRMasKcL+OkrZWwtr+K/b7uQvBwN0y0inUN3EClu56FqfvjiZq4dP4AZY9XTV0Q6jxJECnN3vrZwLVkZxn0fODfZ4YhImlGCSGGL1+1nycZy7rnqbAb2zkt2OCKSZpQgUlTlyQbmL1zPuIG9uO2S4ckOR0TSkBJEitJgfCKSbPrmSUHNg/HdNFWD8YlI8ihBpJh3DcZ3zdhkhyMiaUwJIsU0D8b3levG0Ts/sVniREQSoQSRQpoH47toZF9uuECD8YlIcilBpJDmwfi++UENxiciyacEkSI0GJ+IpBoliBSgwfhEJBVpsL4UoMH4RCQV6Q4iyXYdruZHL2kwPhFJPUoQSfbNZ9djGP9yvQbjE5HUogSRRP+zqZzF6w5w95WjGdRHg/GJSGoJNUGY2Swz22hmW8zs3hj7h5rZEjN708zeMrP3R+37cnDcRjO7Jsw4k+FkQyNfX7iOEcUF3H7ZiGSHIyLyN0JrpDazTOBB4CpgN7DczBa6+/qoYl8FHnP3H5vZucAiYHiwPBc4DxgEvGBmZ7t7Y1jxdraf/3k7ZRVVPPwPF9IjSw3TIpJ6wryDmApscfcyd68DFgBzWpRxoFew3BvYGyzPARa4+0l33wZsCc7XLew7VsOPXtrM1eeWMP0cNUyLSGoydw/nxGY3ArPc/Y5g/VZgmrvPiyozEHgOKAIKgJnuvtLMHgCWufuvg3L/D/ijuz/R4j3uBO4EKCkpmbxgwYJQfpaOUFlZSWFhIQD/ubqWNw828m+X5dE/PzWagaLjS0WKLzGKLzHdOb4ZM2asdPcpsfYl+zmIm4CH3f17ZnYx8CszGx/vwe7+EPAQwJQpU3z69OnhRNkBli5dyvTp03l1awVv/Ol1PjdzDB+eeXaywzqlOb5UpfgSo/gSk67xhZkg9gBDotZLg23RbgdmAbj7a2aWCxTHeWyXU9/YxPyF6xjSN49PvXdUssMREWlTmPUby4ExZjbCzHKINDovbFFmJ3AlgJmNA3KB8qDcXDPrYWYjgDHAGyHG2il+8ep2Nh2o5L7rzyM3Ww3TIpLaQruDcPcGM5sHLAYygZ+7+zoz+wawwt0XAl8Afmpm9xBpsL7NI40i68zsMWA90AB8pqv3YDp6son7X93M9HP6M3OcGqZFJPWF2gbh7ouIdF2N3nZf1PJ64NJWjv0W8K0w4+tMj2+sp66hia994DwN5S0iXUJqdKHp5lZsP8xf9jbwiStGMKK4INnhiIjERQkiZI1Nzr88vY6+ucZnZoxOdjgiInFTggjZb17fwYZ9x5k7Nof8nGT3KhYRiV+7CcLMPmBmSiRn4FDlSb67eCOXju7HhSXqtSQiXUs8X/wfBTab2XfMbGzYAXUn3128keq6RuarYVpEuqB2E4S7/z1wAbAVeNjMXjOzO81MEye3YfWuo/x2xS7+4dLhjCnRpRKRrieuqiN3Pw48QWTAvYHADcAqM7s7xNi6rKYm52tPr6V/YQ/+15WaY1pEuqZ42iBmm9mTwFIgG5jq7tcC7yHyoJu08NiKXazZfYz//f5x9MzNTnY4IiJnJJ5uNX8HfN/dX47e6O7VZnZ7OGF1XUer6/j2n95h6vC+zJk4KNnhiIicsXgSxHxgX/OKmeUBJe6+3d1fDCuwrup7z23iWE09X5+jhmkR6driaYN4HGiKWm8MtkkLa/cc45HXd/Cxi4czbmCv9g8QEUlh8SSIrGBGOACC5ZzwQuqa3J2vLVxHUX4O91yVOvM8iIicqXgSRLmZzW5eMbM5QEV4IXVNT765h5U7jvCla8fSO08N0yLS9cXTBvEp4JFgGlADdgEfCzWqLuZ4bT3/tugdJg7pw42TSpMdjohIh2g3Qbj7VuAiMysM1itDj6qL+cELmzlUdZKf3zaFjAw1TItI9xDX6HFmdh1wHpDb3DPH3b8RYlxdxvHaen7x6nY+OmUIE0r7JDscEZEOE8+Dcj8hMh7T3USqmD4MDAs5ri5j68FKGpqcK8eVJDsUEZEOFU8j9SXu/jHgiLt/HbgYUDedQFl5FQAj+2siIBHpXuJJELXBv9VmNgioJzIekwDbKqrIzDCG9s1PdigiIh0qnjaIP5hZH+C7wCrAgZ+GGVRXUlZRydC++WRnasoMEele2kwQwURBL7r7UeB3ZvYMkOvuxzojuK6grLyKkZpnWkS6oTb/7HX3JuDBqPWTp5MczGyWmW00sy1mdm+M/d83s9XBa5OZHY3a9x0zW2dmG8zsh5aCAxs1NTnbD1UxQglCRLqheOpFXjSzvzvdL2gzyySSXK4FzgVuMrNzo8u4+z3uPtHdJwI/An4fHHsJcCkwARgPXAi893TevzPsO15LbX0TI/sXJjsUEZEOF0+C+CSRwflOmtlxMzthZsfjOG4qsMXdy4LxmxYAc9oofxPwaLDsQC6RMZ96EJmH4kAc79mpysojzwzqDkJEuiNz93BObHYjMMvd7wjWbwWmufu8GGWHAcuAUndvDLb9X+AOIs9ePODuX4lx3J3AnQAlJSWTFyxYEMrP0poXdtTz6w113D89jz65befayspKCgtT905D8SVG8SVG8SUmkfhmzJix0t2nxNrXbi8mM7si1vaWEwglaC7wRFRyGA2MA5oHNnrezC5391daxPAQ8BDAlClTfPr06R0YUvuWLlxHQc4u5lwzo925H5YuXUpnx3c6FF9iFF9iFF9iwoovnm6uX4xaziVSdbQSeF87x+0BhkStlwbbYpkLfCZq/QZgWfO4T2b2RyIP6L0S49ik2Vpeycj+hZoYSES6pXbbINz9A1Gvq4g0Gh+J49zLgTFmNsLMcogkgYUtC5nZWKAIeC1q807gvWaWZWbZRBqoN8Txnp1qW0WVnqAWkW7rTJ7u2k2k+qdN7t4AzAMWE/lyf8zd15nZN6LnlyCSOBb4uxtDngC2Am8Da4A17v6HM4g1NLX1jew5WqMGahHptuJpg/gRkV5FEEkoE4k8Ud0ud18ELGqx7b4W6/NjHNdIpPdUytpxqBp31MVVRLqteNogVkQtNwCPuvtfQoqny2ju4qqnqEWku4onQTwB1Eb1MMo0s3x3rw43tNRWVhEZxVVVTCLSXcX1JDWQF7WeB7wQTjhdR1l5FSW9elDQI645l0REupx4EkRu9DSjwXLaj21dVlHJyGK1P4hI9xVPgqgys0nNK2Y2GagJL6SuQV1cRaS7i6d+5HPA42a2l8iwFwOITEGatg5X1XG0ul7tDyLSrbWbINx9efAw2znBpo3uXh9uWKltW0Wkxm2UuriKSDfWbhWTmX0GKHD3te6+Fig0s7vCDy11bS1XDyYR6f7iaYP4RDCjHADufgT4RGgRdQHbKqrIzjRKi/LaLywi0kXFkyAyoycLCiYCygkvpNRXVh6ZhzpL81CLSDcWTyP1n4Dfmtl/BeufBP4YXkipL9KDSe0PItK9xfMn8JeAl4BPBa+3efeDc2mlscnZfqhaQ2yISLcXz3DfTcDrwHYic0G8jxQceruz7DlSQ11Dk56BEJFur9UqJjM7m8g80TcBFcBvAdx9RueElprKgi6uqmISke6urTaId4jM4Ha9u28BMLN7OiWqFFamLq4ikibaqmL6ELAPWGJmPzWzK4k8SZ3WtlVU0Ss3i34Fad2RS0TSQKsJwt2fcve5wFhgCZEhN84ysx+b2dWdFF/KKauoZITmoRaRNBBPI3WVu//G3T8AlAJvEunZlJa2lVcxStVLIpIGTutJL3c/4u4PufuVYQWUyqrrGth7rFbtDyKSFvQo8GnYXhGZRE89mEQkHShBnIbmLq66gxCRdBBqgjCzWWa20cy2mNm9MfZ/38xWB69NZnY0at9QM3vOzDaY2XozGx5mrPFQF1cRSSehTagcDOr3IHAVsBtYbmYL3X19cxl3vyeq/N3ABVGn+CXwLXd/3swKgaawYo3XtooqBvfJIy8nM9mhiIiELsw7iKnAFncvc/c6YAEwp43yNwGPApjZuUCWuz8PkXmw3b06xFjjUlZeqbsHEUkb5u7hnNjsRmCWu98RrN8KTHP3eTHKDgOWAaXu3mhmHwTuAOqAEcALwL3u3tjiuDuBOwFKSkomL1iwIJSfBcDduevFai4ZlMWt5/Y47eMrKyspLEzdxm3FlxjFlxjFl5hE4psxY8ZKd58Sc6e7h/ICbgR+FrV+K/BAK2W/BPyoxbHHgJFEqsF+B9ze1vtNnjzZw3TweK0P+9Iz/vM/l53R8UuWLOnYgDqY4kuM4kuM4ktMIvEBK7yV79Uwq5j2AEOi1kuDbbHMJaheCuwGVnukeqoBeAqYFEaQ8dpWEWmgVhdXEUkXYSaI5cAYMxthZjlEksDCloXMbCxQBLzW4tg+ZtY/WH8fsL7lsZ2prDwYxVVtECKSJkJLEMFf/vOAxUTmj3jM3deZ2TfMbHZU0bnAguBWp/nYRuCfgBfN7G0igwT+NKxY47GtooqcrAwG9UnbuZJEJM2E1s0VwN0XAYtabLuvxfr8Vo59HpgQWnCnaWt5FSP6FZCZoUH6RCQ96EnqOJVVqIuriKQXJYg4NDQ2sfNQtaYZFZG0ogQRh11Hamhoct1BiEhaUYKIwzbNQy0iaUgJIg7Ng/Spi6uIpBMliDiUVVRRlJ9NkeahFpE0ogQRBw3SJyLpSAkiDtsqqtT+ICJpRwmiHZUnGzhw/KS6uIpI2lGCaMc2NVCLSJpSgmhHmbq4ikiaUoJoR1l5FWYwtG9+skMREelUShDt2FZRRWlRHrnZmodaRNKLEkQ7IoP0qXpJRNKPEkQb3J1t5VVqoBaRtKQE0YaDJ05SVdeoLq4ikpaUINrw1zGYVMUkIulHCaINf+3iqjsIEUk/ShBtKCuvIjc7gwG9cpMdiohIp1OCaMO2iipGFBeSoXmoRSQNKUG0oay8Uj2YRCRthZogzGyWmW00sy1mdm+M/d83s9XBa5OZHW2xv5eZ7TazB8KMM5a6hiZ2HalR+4OIpK2ssE5sZpnAg8BVwG5guZktdPf1zWXc/Z6o8ncDF7Q4zb8CL4cVY1t2Hq6mUfNQi0gaC/MOYiqwxd3L3L0OWADMaaP8TcCjzStmNhkoAZ4LMcZWbasIurhqkD4RSVPm7uGc2OxGYJa73xGs3wpMc/d5McoOA5YBpe7eaGYZwEvA3wMzgSmtHHcncCdASUnJ5AULFnRY/Iu21fHYxnoevDKfguzEG6krKyspLEzdZKP4EqP4EqP4EpNIfDNmzFjp7lNi7Qutiuk0zQWecPfGYP0uYJG77zZr/cvZ3R8CHgKYMmWKT58+vcMC+tOhtyguPMB1V83okPMtXbqUjoyvoym+xCi+xCi+xIQVX5gJYg8wJGq9NNgWy1zgM1HrFwOXm9ldQCGQY2aV7v43Dd1hKSuv0hPUIpLWwkwQy4ExZjaCSGKYC9zcspCZjQWKgNeat7n7LVH7byNSxdRpyQEiT1FfObakM99SRCSlhNZI7e4NwDxgMbABeMzd15nZN8xsdlTRucACD6sx5Awcq6mnorJOXVxFJK2F2gbh7ouARS223ddifX4753gYeLiDQ2tTcw8mdXEVkXSmJ6lj2KZ5qEVElCBiKSuvIjPDNA+1iKQ1JYgYyiqqGFKUR06WLo+IpC99A8ZQVl6l6iURSXtKEC00NTnbK6rUQC0iaU8JooX9x2upqdc81CIiShAtNM9DrTsIEUl3ShAtNHdxHaU2CBFJc0oQLWwtr6IgJ5OzevZIdigiIkmlBNHCtooqRvQvoK1RZEVE0oESRAtlFZWM0CiuIiJKENFONjSy+0gNI9VALSKiBBFtx6Fq3FEXVxERlCDepbmLqyYKEhFRgniXsqCL6wjdQYiIKEFEKyuv4qyePSjskSpTdYuIJI8SRJRtFVVqfxARCShBRCkrVxdXEZFmShCBI1V1HKmuZ5TuIEREACWIU8qCeahVxSQiEqEEEdhW0TyKq6qYREQg5ARhZrPMbKOZbTGze2Ps/76ZrQ5em8zsaLB9opm9ZmbrzOwtM/tomHFCpP0hK8MYUpQX9luJiHQJofXnNLNM4EHgKmA3sNzMFrr7+uYy7n5PVPm7gQuC1WrgY+6+2cwGASvNbLG7Hw0r3m0VVQztl09Wpm6qREQg3DuIqcAWdy9z9zpgATCnjfI3AY8CuPsmd98cLO8FDgL9Q4w1Mg+1qpdERE4JM0EMBnZFre8Otv0NMxsGjABeirFvKpADbA0hRgAam5xth/QMhIhItFR5ZHgu8IS7N0ZvNLOBwK+Aj7t7U8uDzOxO4E6AkpISli5dekZvXl7dRF1DE/WHdrN06YEzOkd7Kisrzzi+zqD4EqP4EqP4EhNafO4eygu4GFgctf5l4MutlH0TuKTFtl7AKuDGeN5v8uTJfqaWbjzow770jC/bWnHG52jPkiVLQjt3R1B8iVF8iVF8iUkkPmCFt/K9GmYV03JgjJmNMLMcIncJC1sWMrOxQBHwWtS2HOBJ4Jfu/kSIMQKwrTwySN9IzUMtInJKaAnC3RuAecBiYAPwmLuvM7NvmNnsqKJzgQVBJmv2EeAK4LaobrATw4q1rKKKnrlZFBfmhPUWIiJdTqhtEO6+CFjUYtt9Ldbnxzju18Cvw4wt2raKKkYWax5qEZFo6vRP0MVV1UsiIu+S9gmitr6RPUdrGKF5qEVE3iXtE0TVyQZmv2cQk4YWJTsUEZGUkirPQSRNv8Ie/PCmC9ovKCKSZtL+DkJERGJTghARkZiUIEREJCYlCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJyd49iGrXZWblwI5kx9GGYqAi2UG0QfElRvElRvElJpH4hrl7zCmdu02CSHVmtsLdpyQ7jtYovsQovsQovsSEFZ+qmEREJCYlCBERiUkJovM8lOwA2qH4EqP4EqP4EhNKfGqDEBGRmHQHISIiMSlBiIhITEoQHcTMhpjZEjNbb2brzOyzMcpMN7NjZrY6eN2XhDi3m9nbwfuviLHfzOyHZrbFzN4ys0mdGNs5UddmtZkdN7PPtSjTqdfQzH5uZgfNbG3Utr5m9ryZbQ7+jTkdoZl9PCiz2cw+3onxfdfM3gl+f0+aWZ9Wjm3zsxBifPPNbE/U7/D9rRw7y8w2Bp/Fezsxvt9GxbbdzFa3cmxnXL+Y3yud9hl0d7064AUMBCYFyz2BTcC5LcpMB55JcpzbgeI29r8f+CNgwEXA60mKMxPYT+QhnqRdQ+AKYBKwNmrbd4B7g+V7gW/HOK4vUBb8WxQsF3VSfFcDWcHyt2PFF89nIcT45gP/FMfvfyswEsgB1rT8/xRWfC32fw+4L4nXL+b3Smd9BnUH0UHcfZ+7rwqWTwAbgMHJjeqMzAF+6RHLgD5mNjAJcVwJbHX3pD4d7+4vA4dbbJ4D/CJY/gXwwRiHXgM87+6H3f0I8DwwqzPic/fn3L0hWF0GlHb0+8arlesXj6nAFncvc/c6YAGR696h2orPzAz4CPBoR79vvNr4XumUz6ASRAjMbDhwAfB6jN0Xm9kaM/ujmZ3XuZEB4MBzZrbSzO6MsX8wsCtqfTfJSXRzaf0/ZrKvYYm77wuW9wMlMcqkynX8RyJ3hLG091kI07ygCuznrVSPpML1uxw44O6bW9nfqdevxfdKp3wGlSA6mJkVAr8DPufux1vsXkWkyuQ9wI+Apzo5PIDL3H0ScC3wGTO7IgkxtMnMcoDZwOMxdqfCNTzFI/fyKdlX3My+AjQAj7RSJFmfhR8Do4CJwD4i1Tip6CbavnvotOvX1vdKmJ9BJYgOZGbZRH6Jj7j771vud/fj7l4ZLC8Css2suDNjdPc9wb8HgSeJ3MpH2wMMiVovDbZ1pmuBVe5+oOWOVLiGwIHmarfg34MxyiT1OprZbcD1wC3BF8jfiOOzEAp3P+Duje7eBPy0lfdN9vXLAj4E/La1Mp11/Vr5XumUz6ASRAcJ6iv/H7DB3f+jlTIDgnKY2VQi1/9QJ8ZYYGY9m5eJNGaubVFsIfAxi7gIOBZ1K9tZWv3LLdnXMLAQaO4R8nHg6RhlFgNXm1lRUIVydbAtdGY2C/hnYLa7V7dSJp7PQljxRbdp3dDK+y4HxpjZiOCOci6R695ZZgLvuPvuWDs76/q18b3SOZ/BMFvg0+kFXEbkNu8tYHXwej/wKeBTQZl5wDoiPTKWAZd0cowjg/deE8TxlWB7dIwGPEikB8nbwJROjrGAyBd+76htSbuGRBLVPqCeSB3u7UA/4EVgM/AC0DcoOwX4WdSx/whsCV7/0InxbSFS99z8OfxJUHYQsKitz0Inxfer4LP1FpEvuoEt4wvW30+k187Wzowv2P5w82cuqmwyrl9r3yud8hnUUBsiIhKTqphERCQmJQgREYlJCUJERGJSghARkZiUIEREJCYlCJHTYGaN9u4RZztslFEzGx49qqhIsmUlOwCRLqbG3ScmOwiRzqA7CJEOEMwN8J1gfoA3zGx0sH24mb0UDEz3opkNDbaXWGSuhjXB65LgVJlm9tNg7P/nzCwvaT+UpD0lCJHTk9eiiumjUfuOufv5wAPA/cG2HwG/cPcJRAbN+2Gw/YfA/3hk0MFJRJ7GBRgDPOju5wFHgb8L9acRaYOepBY5DWZW6e6FMbZvB97n7mXB4Gr73b2fmVUQGUqiPti+z92LzawcKHX3k1HnGE5k/P4xwfqXgGx3/2Yn/Ggif0N3ECIdx1tZPh0no5YbUTuhJJEShEjH+WjUv68Fy68SGYkU4BbglWD5ReDTAGaWaWa9OytIkXjprxOR05Nn757E/k/u3tzVtcjM3iJyF3BTsO1u4L/N7ItAOfAPwfbPAg+Z2e1E7hQ+TWRUUZGUoTYIkQ4QtEFMcfeKZMci0lFUxSQiIjHpDkJERGLSHYSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxPT/ARv0/GV4MbWcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    N_CHARS：字符数量，英文字母转变为One-Hot向量\n",
    "    HIDDEN_SIZE：GRU输出的隐层的维度\n",
    "    N_COUNTRY：分类的类别总数\n",
    "    N_LAYER：GRU层数\n",
    "    '''\n",
    "\n",
    "    HIDDEN_SIZE = 100\n",
    "    BATCH_SIZE = 128\n",
    "    N_LAYER = 2\n",
    "    N_EPOCH = 20\n",
    "    N_CHAR = 128 #ASCII\n",
    "    N_COUNTRY = 18\n",
    "    USE_GPU = False\n",
    "    \n",
    "    trainset = NameDataset(is_train_set = True)\n",
    "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    testset = NameDataset(is_train_set=False)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    #最终的输出维度\n",
    "    N_COUNTRY = trainset.getCountriesNum()\n",
    "    \n",
    "    classifier = RNNClassifier(N_CHAR, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
    "    #迁移至GPU\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs ... \" % N_EPOCH)\n",
    "    #记录训练准确率\n",
    "    acc_list = []\n",
    "    for epoch in range(1, N_EPOCH+1):\n",
    "        #训练模型\n",
    "        trainModel()\n",
    "        #检测模型\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    #绘制图像\n",
    "    epoch = np.arange(1, len(acc_list)+1, 1)\n",
    "    acc_list = np.array(acc_list)\n",
    "    plt.plot(epoch, acc_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ebe47-c3af-4edf-9b47-4801ca0f1b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
